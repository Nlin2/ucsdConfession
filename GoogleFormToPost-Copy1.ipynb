{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5838125b34ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m \u001b[0;31m# image deletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;31m# Names redaction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;31m# Filteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# API support\n",
    "import gspread # Google API\n",
    "import facebook # Facebook API\n",
    "from twython import Twython # Twitter API\n",
    "from oauth2client.service_account import ServiceAccountCredentials # for google api\n",
    "\n",
    "# features\n",
    "import hashlib # Encryption for UserID\n",
    "import re # Images + DM Filtering\n",
    "import requests # Image download\n",
    "import os # image deletion\n",
    "import spacy # Names redaction\n",
    "import sklearn as sk # Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# FB Graph Explorer API\n",
    "\"\"\"\n",
    "FB_PAGE_ACCESS_TOKEN = \"\"\n",
    "FB_PAGE_ID = \"\"\n",
    "graph = facebook.GraphAPI(PAGE_ACCESS_TOKEN)\n",
    "\"\"\"\n",
    "###\n",
    "# Twitter\n",
    "TW_CONSUMER_API = \"\"\n",
    "TW_CONSUMER_SECRET_API = \"\"\n",
    "TW_ACCESS_TOKEN = \"\"\n",
    "TW_ACCESS_TOKEN_SECRET = \"\"\n",
    "twitter = Twython(TW_CONSUMER_API, TW_CONSUMER_SECRET_API, TW_ACCESS_TOKEN, TW_ACCESS_TOKEN_SECRET)\n",
    "###\n",
    "# Google Drive\n",
    "scope =['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "client = gspread.authorize(creds)\n",
    "###\n",
    "\n",
    "INITIAL_COUNTER = 0 # replace me. if you change the txt file, also replace this\n",
    "                    # used to extract the row of the contact information from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashFunc(string):\n",
    "    \"\"\"\n",
    "    Stable hash function\n",
    "    \"\"\"\n",
    "    h = hashlib.blake2b(key=b'ucsdCnfssns', digest_size=10)\n",
    "    h.update(string.encode('UTF-8'))\n",
    "    return h.hexdigest();\n",
    "\n",
    "def downloadImage(imageUrl, localFileName):\n",
    "    \"\"\"\n",
    "    download image\n",
    "    \"\"\"\n",
    "    response = requests.get(imageUrl)\n",
    "    if response.status_code == 200:\n",
    "        print('Downloading %s...' % (localFileName))\n",
    "        with open(localFileName, 'wb') as fo:\n",
    "            for chunk in response.iter_content(4096):\n",
    "                fo.write(chunk)\n",
    "    print(\"Complete Downloading \" + localFileName)\n",
    "\n",
    "def next_available_row(worksheet):\n",
    "    \"\"\"\n",
    "    find the next empty row on google sheets\n",
    "    \"\"\"\n",
    "    str_list = list(filter(None, worksheet.col_values(1)))  # fastest\n",
    "    return str(len(str_list)+1)\n",
    "\n",
    "def clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df\n",
    "\n",
    "def clean_str(s):\n",
    "    \"\"\"\n",
    "    gets rid of punctuations\n",
    "    \"\"\"\n",
    "    return s.lower().apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Number Retrieval\n",
    "with open(\"counter.txt\", \"r\") as c:\n",
    "    counter = int(c.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a workbook by name and open the first sheet\n",
    "# Make sure you use the right name here.\n",
    "toPost = client.open(\"UCSD_Confessions_Form\").sheet1\n",
    "posted = client.open(\"UCSD_Confessions_Form\").worksheet(\"Posted\")\n",
    "\n",
    "toRemove = client.open(\"UCSD Confessions Moderation Form\").sheet1\n",
    "postsRemoved = client.open(\"UCSD Confessions Moderation Form\").worksheet(\"Removed\")\n",
    "notRemove = client.open(\"UCSD Confessions Moderation Form\").worksheet(\"Not Removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print all of the values\n",
    "listOfPosts = toMake.get_all_values()\n",
    "pRemoval = toRemove.get_all_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filteration model\n",
    "m = sk.externals.joblib.load('bnb.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the posts\n",
    "# 0: Timestamp, 1: confession, 2: tag, 3: Contact Info, 4: Images, 5: ID Code\n",
    "for row in listOfPosts[1:]: # TODO: Reverse the iteration so its a stack\n",
    "    counter += 1\n",
    "    # String building\n",
    "    post = f\"#{counter}\\n\" # Number system\n",
    "    post += f\"[{row[2].strip()}]\\n\" # Tag\n",
    "    if (bool(row[5].strip())):\n",
    "        post += f\"User ID: {hashFunc(row[5].strip())}\\n\" # Hash of ID\n",
    "    if (bool(row[3].strip())):\n",
    "        post += f\"Poster has provided contact information\\n\" # Contact info\n",
    "    post += f\"{row[1].strip()}\" # Confession post\n",
    "    \n",
    "    # Insert Filtration System here\n",
    "    # Bayesian spam filter for off topic things\n",
    "    # NER for name redaction\n",
    "    \"\"\"\n",
    "    # spam filter\n",
    "    if m.model.predict_proba(clean_str(post)) > .99: # 1 = Bad post, 0 = good post\n",
    "        posted.resize(next_available_row(posted))\n",
    "        posted.append_row([counter] + row + [False])\n",
    "        #postToMake.delete_row(rowNumber) # TODO: for loop reversal in order to fix this\n",
    "        continue\n",
    "    \"\"\"\n",
    "    \n",
    "    # Edge Case 1: Post is greater than 280\n",
    "    if (len(post) > 280):\n",
    "        numOfPostsRequired = (len(post) - 270) // 260 + 2\n",
    "        # With image\n",
    "        if re.match(r\"^https:\\/\\/i\\.imgur\\.com\\/[a-z0-9A-Z]{7}\\.jpg$\", f\"{row[4].strip()}\"):\n",
    "            initial_p = post[0:270]\n",
    "            initial_p += f\"\\n1/{numOfPostsRequired}\"\n",
    "            \n",
    "            downloadImage(row[4].strip(), \"images/\" + str(counter) + \".jpg\")\n",
    "            photo = open(\"images/\" + str(counter) + \".jpg\", 'rb')\n",
    "\n",
    "            response = twitter.upload_media(media=photo)\n",
    "            postID = twitter.update_status(status=initial_p, media_ids=[response['media_id']])[\"id_str\"]\n",
    "            for index, i in enumerate(range(270, len(post), 260)):\n",
    "                p = \"@UCSDConfession\\n\"\n",
    "                p += post[i: i + 260]\n",
    "                p += f\"\\n{index + 2}/{numOfPostsRequired}\"\n",
    "                postID = twitter.update_status(status=p, in_reply_to_status_id=postID)[\"id_str\"]\n",
    "            photo.close()\n",
    "        # Without image\n",
    "        else:\n",
    "            p = post[0: 270]\n",
    "            p += f\"\\n1/{numOfPostsRequired}\"\n",
    "            postID = twitter.update_status(status=p)[\"id_str\"]\n",
    "            for index, i in enumerate(range(270, len(post), 260)):\n",
    "                p = post[i: i + 260]\n",
    "                p += f\"\\n{index + 2}/{numOfPostsRequired}\"\n",
    "                postID = twitter.update_status(status=p, in_reply_to_status_id=postID)[\"id_str\"]\n",
    "    # Edge Case 2: Images w/ short confession\n",
    "    elif re.match(r\"^https:\\/\\/i\\.imgur\\.com\\/[a-z0-9A-Z]{7}\\.jpg$\", f\"{row[4].strip()}\"):\n",
    "        downloadImage(row[4].strip(), \"images/\" + str(counter) + \".jpg\")\n",
    "        photo = open(\"images/\" + str(counter) + \".jpg\", 'rb')\n",
    "        response = twitter.upload_media(media=photo)\n",
    "        twitter.update_status(status=post, media_ids=[response['media_id']])\n",
    "        os.remove(\"images/\" + str(counter) + \".jpg\")\n",
    "        photo.close()\n",
    "    # Default Case - short confession\n",
    "    else:\n",
    "        twitter.update_status(status=post) \n",
    "    \"\"\"\n",
    "    # For FB posts\n",
    "    graph.put_object(parent_object=PAGE_ID, connection_name='feed',\n",
    "                      message=post)\n",
    "    if row[4] == \"\":\n",
    "        graph.put_object(parent_object=PAGE_ID, connection_name='feed',\n",
    "                      message=post)\n",
    "    else:\n",
    "        # for images\n",
    "        link = row[5]\n",
    "        downloadImage(link, \"images/\" + str(counter) + \".png\")\n",
    "        graph.put_photo(parent_object=PAGE_ID, connection_name='feed', image=open('images/' + str(counter) + '.png', 'rb'),\n",
    "                message=post)\n",
    "    \"\"\"\n",
    "    # Transfer posts to posted\n",
    "    posted.resize(next_available_row(posted))\n",
    "    posted.append_row([counter] + row + [True]) # Make sure to modify to see if it passes filter\n",
    "    #postToMake.delete_row(rowNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFIED_MOD_CODES = [\"\"]\n",
    "# 0: Timestamp, 1: Personal Code, 2: Post ID, 3: Reason for Deletion, 4: Post Number\n",
    "for row in pRemoval[1:]: # reversal\n",
    "    if row[1].strip() not in VERIFIED_MOD_CODES:\n",
    "        notRemoved.resize(next_available_row(postsNotRemoved))\n",
    "        notRemoved.append_row(row)\n",
    "    else:\n",
    "        postsRemoved.resize(next_available_row(postsRemoved))\n",
    "        postsRemoved.append_row(row)\n",
    "        twitter.destroy_status(id=row[2].strip()) # doesn't delete long chained tweets\n",
    "# Delete rows\n",
    "for row in reversed(range(2, len(postToMake.col_values(1)) + 1)):\n",
    "    toMake.delete_row(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Values\n"
     ]
    }
   ],
   "source": [
    "# Delete rows\n",
    "try:\n",
    "    for row in reversed(range(2, len(pRemoval.col_values(1)) + 1)):\n",
    "        pRemoval.delete_row(row)\n",
    "        # len(pRemoval.col_values(1)) + 1 - i???\n",
    "except AttributeError:\n",
    "    print(\"No Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save post number\n",
    "with open(\"counter.txt\", \"w\") as c:\n",
    "    c.write(str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\"\"\"\n",
    "# Automating the replys for people looking for contact information\n",
    "DMs = graph.get_object(PAGE_ID + \"/conversations\", fields=\"snippet\")[\"data\"]\n",
    "messages = []\n",
    "for dm in DMs:\n",
    "    if re.match(r\"^CONTACT_INFO: #\\d+$\", dm[\"snippet\"]):\n",
    "        index = int(re.findall('^CONTACT_INFO: #(\\d+)$',dm[\"snippet\"])[0])\n",
    "        try:\n",
    "            row = posted.row_values(index - INITIAL_COUNTER)\n",
    "            m = f\"Contact Information for post #{index}: \" + posted.row_values(index)[4]\n",
    "            graph.put_object(parent_object=dm[\"id\"], connection_name=\"messages\", message=m)\n",
    "        except:\n",
    "            m = f\"Contact Information for post #{index} is invalid. Please make sure you input the correct value\"\n",
    "            graph.put_object(parent_object=dm[\"id\"], connection_name=\"messages\", message=m)\n",
    "    elif re.match(r\"^CONTACT_INFO: [(#\\d+,?)*#\\d+]$\", dm[\"snippet\"]):\n",
    "        indexesString = re.match(r\"^CONTACT_INFO: ([(#\\d+,?)*#\\d+])$\", dm[\"snippet\"])\n",
    "        indexes = indexesString.strip('][').split(',')\n",
    "        for i in indexes:\n",
    "            stringIndex = i.strip(\" \").strip(\"#\")\n",
    "            try:\n",
    "                index = int(stringIndex)\n",
    "                row = posted.row_values(index)\n",
    "                messages.append(f\"Contact Information for post #{index}: \" + posted.row_values(index)[4])\n",
    "                graph.put_object(parent_object=dm[\"id\"], connection_name=\"messages\", message=m)\n",
    "            except ValueError:\n",
    "                messages.append(f\"#{stringIndex} is not a valid post number\")\n",
    "            except APIError:\n",
    "                messages.append(f\"Contact Information for post #{index} does not exist. Please make sure you input the correct value\")\n",
    "        for m in messages:\n",
    "            graph.put_object(parent_object=dm[\"id\"], connection_name=\"messages\", message=m)\n",
    "\"\"\"\n",
    "###\n",
    "# TODO: Twitter replies. Look at twitter api."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
